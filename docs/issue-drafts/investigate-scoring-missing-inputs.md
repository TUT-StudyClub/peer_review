# [Investigate] review_contribution: 未入力（欠損）時の扱い

## 調査したいこと

`review_contribution`（レビュー貢献点）の算出に使う各成分が **未入力（欠損）** のとき、どの扱いを採用するかを決める。

対象の成分（現行の簡易式）：
- `helpfulness`（メタ評価: 1〜5）
- `alignment`（teacher採点との一致度: 0〜1）
- `quality`（AI品質: 1〜5）

## 調査の背景

レビュー貢献点は「レビューの質」だけでなく「役に立ったか（メタ評価）」や「teacher採点と一致しているか（alignment）」も混ぜて算出している。
一方で、以下の理由で **欠損が自然に発生** する：

- `helpfulness`: 提出者がメタ評価をしない/遅れると欠損
- `alignment`: teacherが採点しない/遅れると欠損（teacher rubric が無いと一致度が計算できない）
- `quality`: 通常はレビュー提出時にAI（または簡易判定）で付与されるが、既存データ/例外時には欠損しうる

欠損があると、スコアが **不自然に高い/低い**、または **説明しづらい** 可能性があるため、方針を固定して仕様化する。

## ゴール（Output）

- [ ] 採用案（どれを選ぶか）と理由（Why）がIssueに残っている
- [ ] 期待する挙動（仕様）が文章化されている
- [ ] 実装タスクに落とせる粒度になっている

---

## 選択肢

### A. 中立値固定（例: 0.6）で埋める

**概要**
- 欠損した成分を「中立値（例: 0.6）」として扱い、常に同じ重みで加重平均する

**メリット**
- 実装が簡単
- 欠損の有無で重みが変わらないため、挙動が単純

**デメリット**
- 欠損を「平均的」とみなす恣意性がある（根拠が弱い）
- 欠損が多いほど、実際に観測できている成分（例: `quality`）の影響が薄まり、低品質レビューが救済される/高品質が伸びない可能性

**向いているケース**
- 「欠損のときは平均的で良い」というプロダクト方針が明確にある場合

### B. 欠損した成分は除外し、残りの重みを再配分（= 正規化）する

**概要**
- 欠損した成分はスコア計算から除外する
- 利用可能な成分の重みを `sum=1` になるように再配分して加重平均する

**メリット**
- 欠損に対して恣意的な値を置かない（観測できた情報だけで評価）
- 欠損が「他者要因（teacher未採点/提出者未メタ評価）」で起きても、レビュアーが一方的に損をしづらい
- breakdown で「今回どの成分が使われたか/重みがどうなったか」を説明しやすい

**デメリット**
- 欠損の有無で重みが変わるため、同じ `quality` でも状況により点が変わる（説明が必要）
- 例: `helpfulness` と `alignment` が欠損すると `quality` の重みが 1.0 になり、点の振れ幅が大きくなる

**向いているケース**
- 欠損を「未知」と捉え、推測で埋めたくない場合
- MVP段階で、実装の複雑化を避けつつ説明可能性を重視したい場合

### C. 代替（近似）で欠損成分を推定する（例: ピア中央値）

**概要**
- 欠損した成分（特に `alignment`）を、別のデータから推定して近似値を入れる
  - 例: teacher rubric が無い場合、同じ提出物に対する他ピアレビューの rubric スコアの中央値（/平均）を「暫定の正解」とみなし、そこから一致度を計算する

**メリット**
- teacher未採点でも `alignment` 相当のシグナルを早期に使える
- 欠損時の点の振れ幅を抑えやすい

**デメリット**
- 実装が複雑（クエリ/集計/除外ロジック/レビュー数が少ない時の扱い）
- 「teacherとの一致」ではなく「同調（peer consensus）」に寄るため、狙いが変わる（herding を誘発しうる）
- 将来 teacher採点が入ったときに、近似値とどちらを採用するかで仕様が難しくなる

**向いているケース**
- 一致度を強く効かせたい & teacher採点が遅れる/無い運用が多い場合
- 将来の高度化（第2フェーズ）として切り出すのが安全

---

## 結論（採用案）

**採用: B（欠損成分を除外し、残りの重みを再配分）**

理由：
- 欠損は「未観測」であり、固定値で埋めるよりも **観測できた情報のみ** で評価するほうが恣意性が低い
- 欠損が teacher/提出者側の都合で起きても、レビュアーが不利益を受けにくい（フェア）
- `breakdown` に「欠損/重み再配分」を出せば、UI/運用上の説明がしやすい
- 代替推定（C）は有効だが、MVP段階では複雑度/副作用が大きい

---

## 仕様（期待する挙動）

### 1) 基本式（1レビューあたり最大10点）

ベース重み（固定）：
- `helpfulness`: 0.5
- `alignment`: 0.3
- `quality`: 0.2

各成分の正規化：
- `helpfulness_norm = helpfulness / 5`（`helpfulness` がある場合）
- `alignment_norm = alignment`（0〜1、計算できる場合）
- `quality_norm = quality / 5`（`quality` がある場合）

欠損ルール（採用案 B）：
- 欠損した成分は「計算に使わない（weight=0）」。
- 利用可能な成分だけで、重みを `sum=1` になるよう正規化する。

例（teacher未採点で `alignment` 欠損）：
- 利用可能: `helpfulness(0.5)`, `quality(0.2)`
- 正規化後: `helpfulness=0.5/0.7`, `quality=0.2/0.7`

点数：
- `points = 0` if toxic
- `points = 10 * score_norm` otherwise
- `score_norm = Σ(weight_i * norm_i)`（利用可能な成分のみ）

### 2) スコアの更新タイミング

- `helpfulness`（メタ評価）や teacher採点が後から追加されると、`review_contribution` / `final_score` は **再計算され変動しうる**
- 変動は仕様として許容し、UI/README で注記する

### 3) breakdown（内訳）の要件

期待する `breakdown` 例（キー名は実装に合わせる）：
- ベース重み（固定値）
- 各レビューごとの
  - どの成分が欠損だったか
  - 正規化後の重み
  - raw/norm 値
  - 合成後 `score_norm` と `points`

---

## 実装タスク案（Taskに落とす）

### backend
- [ ] 欠損成分の除外 + 重み再配分のロジックを実装
- [ ] `breakdown` に「欠損/重み/各成分の値」を含める
- [ ] 互換性（既存データで `ai_quality_score` が欠損しても落ちない等）を確認

### frontend
- [ ] Grade表示に「欠損時は除外して重み再配分」の注記を追加
- [ ] `breakdown` を表示する（少なくとも JSON で可視化）

### docs
- [ ] README（または docs）に、欠損時の扱い（採用案B）と、スコアが後から変動しうる旨を記載

### option（将来）
- [ ] 近似案（C: ピア中央値）を別Issueで調査/試作（レビュー数が少ない場合の扱い含む）

---

## 現状（実装状況）

このリポジトリ上では、採用案B（欠損除外 + 重み再配分）を以下で実装済み：
- backend: `backend/app/services/scoring.py`（`breakdown` に重み/欠損/内訳を含める）
- frontend: `frontend/src/app/assignments/[assignmentId]/page.tsx`（注記を表示）
- docs: `README.md`（欠損時は除外して重みを再配分する旨を記載）

（Issue化する場合は、上記実装を前提として「仕様決定の記録」として残し、将来案Cは別Issueに切り出す）

---

## 参考（実装/関連ファイル）

- backend: `backend/app/services/scoring.py`
- frontend: `frontend/src/app/assignments/[assignmentId]/page.tsx`
- docs: `README.md`
